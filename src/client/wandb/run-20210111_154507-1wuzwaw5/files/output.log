Train Epoch: 1 [0/2608 (0%)]	Loss: 0.000084
Train Epoch: 1 [400/2608 (15%)]	Loss: 0.000007
Train Epoch: 1 [800/2608 (31%)]	Loss: 0.000000
Train Epoch: 1 [1200/2608 (46%)]	Loss: 0.000275
Train Epoch: 1 [1600/2608 (61%)]	Loss: 0.000000
Train Epoch: 1 [2000/2608 (77%)]	Loss: 0.000000
Train Epoch: 1 [2400/2608 (92%)]	Loss: 0.084540
Train Epoch: 2 [0/2608 (0%)]	Loss: 0.000000
Train Epoch: 2 [400/2608 (15%)]	Loss: 0.000001
Train Epoch: 2 [800/2608 (31%)]	Loss: 0.000003
Train Epoch: 2 [1200/2608 (46%)]	Loss: 0.000000
Train Epoch: 2 [1600/2608 (61%)]	Loss: 0.055701
Train Epoch: 2 [2000/2608 (77%)]	Loss: 0.000015
Train Epoch: 2 [2400/2608 (92%)]	Loss: 0.000003
Train Epoch: 3 [0/2608 (0%)]	Loss: 0.000021
Train Epoch: 3 [400/2608 (15%)]	Loss: 0.000000
Train Epoch: 3 [800/2608 (31%)]	Loss: 0.000002
Train Epoch: 3 [1200/2608 (46%)]	Loss: 0.000003
Train Epoch: 3 [1600/2608 (61%)]	Loss: 0.001438
Train Epoch: 3 [2000/2608 (77%)]	Loss: 0.000005
Train Epoch: 3 [2400/2608 (92%)]	Loss: 0.000000
Train Epoch: 4 [0/2608 (0%)]	Loss: 0.000006
Train Epoch: 4 [400/2608 (15%)]	Loss: 0.000017
Train Epoch: 4 [800/2608 (31%)]	Loss: 0.000000
Train Epoch: 4 [1200/2608 (46%)]	Loss: 0.000000
Train Epoch: 4 [1600/2608 (61%)]	Loss: 0.000001
Train Epoch: 4 [2000/2608 (77%)]	Loss: 0.000002
Train Epoch: 4 [2400/2608 (92%)]	Loss: 0.000002
model sent successfully!
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Waiting for aggregation...
Train Epoch: 1 [0/2608 (0%)]	Loss: 0.000000
Train Epoch: 1 [400/2608 (15%)]	Loss: 0.000014
Train Epoch: 1 [800/2608 (31%)]	Loss: 0.000000
Train Epoch: 1 [1200/2608 (46%)]	Loss: 0.000000
Train Epoch: 1 [1600/2608 (61%)]	Loss: 0.002230
Train Epoch: 1 [2000/2608 (77%)]	Loss: 0.004763
Train Epoch: 1 [2400/2608 (92%)]	Loss: 0.000000
Train Epoch: 2 [0/2608 (0%)]	Loss: 0.000833
Train Epoch: 2 [400/2608 (15%)]	Loss: 0.000104
Train Epoch: 2 [800/2608 (31%)]	Loss: 0.000000
Train Epoch: 2 [1200/2608 (46%)]	Loss: 0.000000
Train Epoch: 2 [1600/2608 (61%)]	Loss: 0.000096
Train Epoch: 2 [2000/2608 (77%)]	Loss: 0.000020
Train Epoch: 2 [2400/2608 (92%)]	Loss: 0.000000
Train Epoch: 3 [0/2608 (0%)]	Loss: 0.000000
Train Epoch: 3 [400/2608 (15%)]	Loss: 0.000040
Train Epoch: 3 [800/2608 (31%)]	Loss: 0.000017
Train Epoch: 3 [1200/2608 (46%)]	Loss: 0.000001
Train Epoch: 3 [1600/2608 (61%)]	Loss: 0.000000
Train Epoch: 3 [2000/2608 (77%)]	Loss: 0.000000
Train Epoch: 3 [2400/2608 (92%)]	Loss: 0.000008
Train Epoch: 4 [0/2608 (0%)]	Loss: 0.000000
Train Epoch: 4 [400/2608 (15%)]	Loss: 0.000006
Train Epoch: 4 [800/2608 (31%)]	Loss: 0.000000
Train Epoch: 4 [1200/2608 (46%)]	Loss: 0.000000
Train Epoch: 4 [1600/2608 (61%)]	Loss: 0.000000
Train Epoch: 4 [2000/2608 (77%)]	Loss: 0.000000
Train Epoch: 4 [2400/2608 (92%)]	Loss: 0.000000
model sent successfully!
Waiting for aggregation...
Train Epoch: 1 [0/2608 (0%)]	Loss: 0.000000
Train Epoch: 1 [400/2608 (15%)]	Loss: 0.000000
Train Epoch: 1 [800/2608 (31%)]	Loss: 0.000000
Train Epoch: 1 [1200/2608 (46%)]	Loss: 0.000058
Train Epoch: 1 [1600/2608 (61%)]	Loss: 0.040698
Traceback (most recent call last):
  File "run.py", line 46, in <module>
    optimizer=optimizer, epoch=epoch)                ###logger added
  File "C:\Users\kevin\OneDrive\Documents\8th sem\Federated_Pneumonia\src\client\train.py", line 7, in train
    for batch_idx, (data, target) in enumerate(train_loader): # <-- now it is a distributed dataset
  File "C:\Users\kevin\anaconda3\envs\fl\lib\site-packages\torch\utils\data\dataloader.py", line 345, in __next__
    data = self._next_data()
  File "C:\Users\kevin\anaconda3\envs\fl\lib\site-packages\torch\utils\data\dataloader.py", line 385, in _next_data
    data = self._dataset_fetcher.fetch(index)  # may raise StopIteration
  File "C:\Users\kevin\anaconda3\envs\fl\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in fetch
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\kevin\anaconda3\envs\fl\lib\site-packages\torch\utils\data\_utils\fetch.py", line 44, in <listcomp>
    data = [self.dataset[idx] for idx in possibly_batched_index]
  File "C:\Users\kevin\OneDrive\Documents\8th sem\Federated_Pneumonia\src\client\dataloader.py", line 51, in __getitem__
    image = PIL.ImageOps.grayscale(image)
  File "C:\Users\kevin\anaconda3\envs\fl\lib\site-packages\PIL\ImageOps.py", line 476, in grayscale
    return image.convert("L")
  File "C:\Users\kevin\anaconda3\envs\fl\lib\site-packages\PIL\Image.py", line 893, in convert
    self.load()
  File "C:\Users\kevin\anaconda3\envs\fl\lib\site-packages\PIL\ImageFile.py", line 265, in load
    n, err_code = decoder.decode(b)
KeyboardInterrupt
