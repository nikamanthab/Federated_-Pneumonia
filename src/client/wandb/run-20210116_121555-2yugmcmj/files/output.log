--- Connection established ---
--- Dataset loaded ---
--- model loaded ---
Train Epoch: 1 [0/2608 (0%)]	Loss: 0.647074
Train Epoch: 1 [100/2608 (4%)]	Loss: 1.474929
Train Epoch: 1 [200/2608 (8%)]	Loss: 0.431610
Train Epoch: 1 [300/2608 (12%)]	Loss: 0.741752
Train Epoch: 1 [400/2608 (15%)]	Loss: 0.173709
Train Epoch: 1 [500/2608 (19%)]	Loss: 0.818185
Train Epoch: 1 [600/2608 (23%)]	Loss: 0.368463
Train Epoch: 1 [700/2608 (27%)]	Loss: 0.847118
Train Epoch: 1 [800/2608 (31%)]	Loss: 0.769275
Train Epoch: 1 [900/2608 (35%)]	Loss: 0.878786
Train Epoch: 1 [1000/2608 (38%)]	Loss: 0.803443
Train Epoch: 1 [1100/2608 (42%)]	Loss: 0.840370
Train Epoch: 1 [1200/2608 (46%)]	Loss: 0.364695
Train Epoch: 1 [1300/2608 (50%)]	Loss: 0.222979
Train Epoch: 1 [1400/2608 (54%)]	Loss: 0.296776
Train Epoch: 1 [1500/2608 (58%)]	Loss: 0.773491
Train Epoch: 1 [1600/2608 (61%)]	Loss: 0.269611
Train Epoch: 1 [1700/2608 (65%)]	Loss: 0.272536
Train Epoch: 1 [1800/2608 (69%)]	Loss: 0.789871
Train Epoch: 1 [1900/2608 (73%)]	Loss: 0.358214
Train Epoch: 1 [2000/2608 (77%)]	Loss: 0.247714
Train Epoch: 1 [2100/2608 (81%)]	Loss: 0.307897
Traceback (most recent call last):
  File "run.py", line 47, in <module>
    optimizer=optimizer, epoch=epoch)                ###logger added
  File "/home/nikamanth/Documents/fyp/src/client/train.py", line 13, in train
    optimizer.step()
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/site-packages/torch/optim/adam.py", line 96, in step
    exp_avg_sq.mul_(beta2).addcmul_(1 - beta2, grad, grad)
KeyboardInterrupt
