Aggregation Epoch Number: 1
False
False
False
False
False
False
False
False
Saving to: ../aggregated_model/agg_model.pt

Test set: Average loss: 0.6830, Accuracy: 390/624 (62%)

Aggregation Epoch Number: 2
Traceback (most recent call last):
  File "run.py", line 20, in <module>
    parallel_run.runTrainParallel(nodelist, datasample_count, args, FLdataloaders, testloader)
  File "/home/nikamanth/Documents/fyp/programs/parallel_run.py", line 51, in runTrainParallel
    node_model_list = loop.run_until_complete(collectModels(nodelist, args, agg_model, FLdataloaders))
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/asyncio/base_events.py", line 574, in run_until_complete
    self.run_forever()
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/asyncio/base_events.py", line 541, in run_forever
    self._run_once()
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/asyncio/base_events.py", line 1786, in _run_once
    handle._run()
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/asyncio/events.py", line 88, in _run
    self._context.run(self._callback, *self._args)
  File "/home/nikamanth/Documents/fyp/programs/parallel_run.py", line 25, in runOnNode
    optimizer=optimizer, epoch=epoch)
  File "/home/nikamanth/Documents/fyp/programs/train.py", line 7, in train
    for batch_idx, (data, target) in enumerate(train_loader): # <-- now it is a distributed dataset
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/site-packages/syft/frameworks/torch/fl/dataloader.py", line 250, in __next__
    data, target = next(iterator)
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/site-packages/syft/frameworks/torch/fl/dataloader.py", line 102, in __next__
    batch = self._get_batch()
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/site-packages/syft/frameworks/torch/fl/dataloader.py", line 85, in _get_batch
    batch = self.collate_fn([self.federated_dataset[worker][i] for i in indices])
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/site-packages/syft/frameworks/torch/fl/dataloader.py", line 85, in <listcomp>
    batch = self.collate_fn([self.federated_dataset[worker][i] for i in indices])
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/site-packages/syft/frameworks/torch/fl/dataset.py", line 52, in __getitem__
    data_elem = self.data[index]
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook.py", line 221, in overloaded_native_method
    wrap_args=self.get_class_attributes(),
  File "/home/nikamanth/anaconda3/envs/torch/lib/python3.7/site-packages/syft/generic/frameworks/hook/hook_args.py", line 195, in hook_response
    def hook_response(attr, response, wrap_type, wrap_args={}, new_self=None):
KeyboardInterrupt
